{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2128ddf8-a751-4287-9562-78f08493d367",
   "metadata": {},
   "source": [
    ">AlexNet - f1-score = 0.728075 with Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b21a12-921e-43e6-a358-1a1c5a19c93a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.models import alexnet\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2f270-b389-4ffe-9bb4-f0e114cbd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f77b92-0e7d-4e52-b098-7db857a194c4",
   "metadata": {},
   "source": [
    "#### Preparation train and test date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2db6c3-f9c8-4a4c-affb-06d5cc73a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './data/journey-springfield/train/simpsons_dataset'\n",
    "test_data_path = './data/journey-springfield/testset'\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_image_folder = ImageFolder(root=train_data_path, transform=train_transform)\n",
    "test_image_folder = ImageFolder(root=test_data_path, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89f3761-f14d-4f0d-9244-90cce9b0dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "valid_size = 0.2\n",
    "train_dataset, valid_dataset = random_split(train_image_folder, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40abb26-7784-4f73-825f-2537c62d15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "# train_loader = DataLoader(dataset=train_image_folder, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# valid_loader = DataLoader(dataset=test_image_folder, shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859c7c1-1269-46d2-a833-eefd25912130",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593efe6e-8c9a-44c3-9a8e-b0456f80eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trainig(train_losses, valid_loss):\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(train_losses, label='train_loss')\n",
    "    plt.plot(valid_losses, label='valid_loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45ea1c4-4f0c-4a36-b41a-12a84252c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ImageNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n",
    "#         self.fc1 = nn.Linear(in_features=6400, out_features=4096)\n",
    "#         self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "#         self.fc3 = nn.Linear(in_features=4096, out_features=42)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x), inplace=True)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "#         x = F.relu(self.conv2(x), inplace=True)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "#         x = F.relu(self.conv3(x), inplace=True)\n",
    "#         x = F.relu(self.conv4(x), inplace=True)\n",
    "#         x = F.relu(self.conv5(x), inplace=True)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = F.dropout(x, p=0.5)\n",
    "#         x = F.relu(self.fc1(x), inplace=True)\n",
    "#         x = F.dropout(x, p=0.5)\n",
    "#         x = F.relu(self.fc2(x), inplace=True)\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "AlexNet = alexnet()\n",
    "AlexNet.classifier[4] = nn.Linear(4096, 1024)\n",
    "AlexNet.classifier[6] = nn.Linear(1024, 42)\n",
    "AlexNet = AlexNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85fc40b-a375-4d17-9ad9-1a9f5d93d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, scheduler):\n",
    "    train_losses = []\n",
    "    # valid_losses = []\n",
    "    # valid_f1 = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        for xb, yb in tqdm(train_dl, desc=f'{epoch+1} st train loop'):\n",
    "            xb, yb, = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss_sum += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        train_losses.append(loss_sum / len(train_dl))\n",
    "        scheduler.step()\n",
    "\n",
    "        # model.eval()\n",
    "        # loss_sum = 0\n",
    "        # predictions = []\n",
    "        # true_labels = []\n",
    "        # with torch.no_grad():\n",
    "        #     for x, y in tqdm(valid_dl, desc=f'{epoch+1} st valid loop'):\n",
    "        #         probs = model(x)\n",
    "        #         loss_sum += loss_func(probs, y).item()\n",
    "        #         y_pred = torch.argmax(probs, dim=-1)\n",
    "        #         true_labels.append(y.item())\n",
    "        #         predictions.append(y_pred.item())\n",
    "        # valid_losses.append(loss_sum / len(valid_dl))\n",
    "        # f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "        # valid_f1.append(f1)\n",
    "\n",
    "        # print(f'Epoch {epoch+1}: Train Loss = {train_losses[-1]}, Valid Loss = {valid_losses[-1]}, F1-score = {f1}')\n",
    "        print(f'Epoch {epoch+1}: Train Loss = {train_losses[-1]},  Lr = {scheduler.get_last_lr()}')\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(AlexNet.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(opt, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90fb84e5-73bc-4f87-a5a5-3306177a06a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f923f7d8b9444a618787e941f9f80ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1 st train loop:   0%|          | 0/2094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 3.1384564964910178,  Lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b243ac635d943daabf1637717e0032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2 st train loop:   0%|          | 0/2094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 3.1208700817202883,  Lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c473c1acf3aa46cebaf3adab6027ffe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3 st train loop:   0%|          | 0/2094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 3.116413153686633,  Lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf762c40644fcab64440f273ae6300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4 st train loop:   0%|          | 0/2094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 3.115189084350892,  Lr = [0.001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5ac7dd7cf64b1387f03dc2729b5d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5 st train loop:   0%|          | 0/2094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAlexNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plot_trainig(info)\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(model(xb), yb)\n\u001b[0;32m---> 13\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "info = fit(epochs, AlexNet, loss_func, opt, train_loader, scheduler)\n",
    "plot_trainig(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1c34051-6ccb-4948-81e6-b320fff99fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        output = model(x)\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        _, y_pred_class = torch.max(probs, dim=-1)\n",
    "        y_pred_name_class = class_names[y_pred_class]\n",
    "        y_pred.append(y_pred_name_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dd6a240-13fd-4046-bd15-fffab5306ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img0.jpg</td>\n",
       "      <td>moe_szyslak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>charles_montgomery_burns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>ned_flanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>chief_wiggum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>apu_nahasapeemapetilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>img986.jpg</td>\n",
       "      <td>nelson_muntz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>img987.jpg</td>\n",
       "      <td>apu_nahasapeemapetilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>img988.jpg</td>\n",
       "      <td>charles_montgomery_burns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>img989.jpg</td>\n",
       "      <td>chief_wiggum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>img990.jpg</td>\n",
       "      <td>marge_simpson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                  Expected\n",
       "0      img0.jpg               moe_szyslak\n",
       "1      img1.jpg  charles_montgomery_burns\n",
       "2      img2.jpg              ned_flanders\n",
       "3      img3.jpg              chief_wiggum\n",
       "4      img4.jpg    apu_nahasapeemapetilon\n",
       "..          ...                       ...\n",
       "986  img986.jpg              nelson_muntz\n",
       "987  img987.jpg    apu_nahasapeemapetilon\n",
       "988  img988.jpg  charles_montgomery_burns\n",
       "989  img989.jpg              chief_wiggum\n",
       "990  img990.jpg             marge_simpson\n",
       "\n",
       "[991 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv('./data/journey-springfield/sample_submission.csv')\n",
    "df_sub['Expected'] = y_pred\n",
    "df_sub.to_csv('df_sub.csv', index=False)\n",
    "df_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
