{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4122615-4696-430c-945c-4c290a5fcc6a",
   "metadata": {},
   "source": [
    "* LogReg \n",
    "    > Accuracy = 0.84\n",
    "    > \n",
    "    > ROC-AUC = 0.88409\n",
    "* SVC\n",
    "    > Accuracy = 0.87\n",
    "    > \n",
    "    > ROC-AUC = 0.93501\n",
    "* Neural Network\n",
    "    > Accuracy = 0.875\n",
    "    >\n",
    "    > ROC-AUC = 0.9507035\n",
    "* Boosting (catBoost)\n",
    "    > Accuracy = 0.915\n",
    "    >\n",
    "    > ROC-AUC = 0.96335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5870a510-d82f-49e2-816b-70ebcbe9646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec891780-0371-44b7-82ac-1a56c2d11ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv', header=None)\n",
    "df_y = pd.read_csv('./data/trainLabels.csv', header=None).values\n",
    "df_test = pd.read_csv('./data/test.csv', header=None)\n",
    "df_sub = pd.DataFrame({\n",
    "    'Id' : range(1, len(df_test)+1),\n",
    "    'Solution' : 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c195840-410e-4b6c-8c30-db38ee853750",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_train = scaler.fit_transform(df_train.values)\n",
    "df_test = scaler.fit_transform(df_test.values)\n",
    "df_train = pd.DataFrame(df_train)\n",
    "df_test = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e56bfd-65ca-4650-a23a-f8b009841a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_train, df_y, test_size=0.2, random_state=0)\n",
    "# y_train = y_train.ravel()\n",
    "# y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17399076-fde6-4d10-9bc0-54959c569052",
   "metadata": {},
   "source": [
    "#### Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de76a77a-8f86-477d-80a1-43832c91baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "461779f9-293b-4863-a84e-ce3f2ceb7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = BayesianGaussianMixture(n_components=7, n_init=3)\n",
    "gmm.fit(x_all)\n",
    "X_train = gmm.predict_proba(df_train)\n",
    "X_test = gmm.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6feda-b3cf-4445-b4ee-1074577feebc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5974b9b-1be6-491e-a6df-8f0603cbe8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# y_score = clf.predict_proba(X_test)\n",
    "\n",
    "# clf.fit(df_train, df_y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592bcfe-66d3-4b54-9e79-7f48af2e2e86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd63ed-af3c-4602-abe1-092bddbf7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# y_score = clf.predict_proba(X_test)\n",
    "\n",
    "clf.fit(df_train, df_y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8f6c4-f903-40ae-958e-ac2e37de595a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9b8d0af0-9caa-4a7b-b37a-cfc17d1cfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "# X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "# y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "X_train_t = torch.tensor(df_train, dtype=torch.float32)\n",
    "X_test_t = torch.tensor(df_test, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(df_y.ravel(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c7c772fa-36db-4ba0-94f3-cb11259ee180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ff1afe27-4465-4f66-be37-02ef822e39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(clf, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=40, out_features=25)\n",
    "        self.fc2 = nn.Linear(in_features=25, out_features=10)\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu6(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = clf()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7ee7f60c-a7fb-42c3-8d6c-d3114d17dbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  loss = 0.11654\n",
      "Epoch: 2,  loss = 0.0\n",
      "Epoch: 3,  loss = 0.15109\n",
      "Epoch: 4,  loss = 0.20077\n",
      "Epoch: 5,  loss = 0.00222\n",
      "Epoch: 6,  loss = 0.09346\n",
      "Epoch: 7,  loss = 0.01554\n",
      "Epoch: 8,  loss = 0.07233\n",
      "Epoch: 9,  loss = 1e-05\n",
      "Epoch: 10,  loss = 0.0\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "history_loss = []\n",
    "num_epoch = 10\n",
    "for epoch in range(num_epoch):\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # scheduler.step()\n",
    "    _loss = loss.detach().numpy().tolist()\n",
    "    history_loss.append(_loss)\n",
    "    print(f'Epoch: {epoch+1},  loss = {round(_loss, 5)}')\n",
    "    # print(f'Epoch: {epoch+1},  lr = {round(scheduler.get_last_lr()[0], 5)},  loss = {round(_loss, 5)}')\n",
    "\n",
    "print('----------------------')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test_t)\n",
    "    probabilities = F.softmax(y_pred, dim=1)\n",
    "    _, predicted = torch.max(probabilities, 1)\n",
    "predicted_classes = predicted.numpy()\n",
    "# print(f'Accuracy = {accuracy_score(y_test, predicted_classes)}')\n",
    "# print(f'ROC-AUC = {roc_auc_score(y_test, probabilities[:, 1].numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d199e4d-c0f0-40ee-acd9-7fdfc4c36e79",
   "metadata": {},
   "source": [
    "#### CatBoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea9017-0dc3-4c93-9a91-620facfa5d9f",
   "metadata": {},
   "source": [
    "#### LightG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67df9696-ed34-4d05-91a6-c47b76945c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 510, number of negative: 490\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510000 -> initscore=0.040005\n",
      "[LightGBM] [Info] Start training from score 0.040005\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For early stopping, at least one dataset and eval metric is required for evaluation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,  metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# clf.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# y_pred = clf.predict(X_test)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# y_score = clf.predict_proba(X_test)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# clf.fit(df_train, df_y.ravel())\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/sklearn.py:1142\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1142\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    840\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n\u001b[0;32m--> 276\u001b[0m         \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCallbackEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                                \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbegin_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mend_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mEarlyStopException \u001b[38;5;28;01mas\u001b[39;00m earlyStopException:\n\u001b[1;32m    283\u001b[0m     booster\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m=\u001b[39m earlyStopException\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/callback.py:353\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback.__call__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: CallbackEnv) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m==\u001b[39m env\u001b[38;5;241m.\u001b[39mbegin_iteration:\n\u001b[0;32m--> 353\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightgbm/callback.py:293\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback._init\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\u001b[38;5;241m.\u001b[39mevaluation_result_list:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor early stopping, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    294\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least one dataset and eval metric is required for evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopping_rounds \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopping_rounds should be greater than zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: For early stopping, at least one dataset and eval metric is required for evaluation"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(objective='binary',  metric='accuracy', n_jobs=-1)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# y_score = clf.predict_proba(X_test)\n",
    "\n",
    "# clf.fit(df_train, df_y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e511b-95fe-4412-8df7-3ad87149159a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### evalution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc737870-6507-45b2-bc0a-c6fc937cab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.88\n",
      "ROC-AUC = 0.9530316833687621\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy = {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC = {roc_auc_score(y_test, y_score[:, 1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f33ef8-7f19-49b6-b9c6-a9f0f4da0a42",
   "metadata": {},
   "source": [
    "#### Predict and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3157904-ea24-44d4-83b1-0977be591d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "# y_pred = predicted_classes\n",
    "df_sub['Solution'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b8450a5-94af-4b61-a0be-30bc95c09a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('london.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
