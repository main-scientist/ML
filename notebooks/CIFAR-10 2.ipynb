{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab245bba-6549-4773-a2c1-ab949b71bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897cc6bc-434a-41e1-80d9-700e6fcee9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe96b641-7f17-4880-a0aa-2cd79a0d0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)  # Вход: 32x32, Выход: 32x32\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.drop1 = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)  # Вход: 32x32, Выход: 32x32\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Вход: 32x32, Выход: 16x16\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)  # Вход: 16x16, Выход: 16x16\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Вход: 16x16, Выход: 8x8\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1)  # Вход: 8x8, Выход: 6x6\n",
    "        self.norm4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=4)  # Вход: 6x6, Выход: 1x1\n",
    "        self.drop2 = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=64, out_features=256)\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.norm3(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.norm4(x)\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a80f92-9a58-4c3b-879e-a39e30ec612d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faf54c4-ea6b-4b91-b8af-693a950da987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bf47b6-67e8-44ef-b3fe-d9da556e6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e900a6b-1bcb-4dfa-8655-47bd96507e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e6e52d-0be1-4438-9499-33ddf921ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=400, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x      \n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.MultiStepLR(opt, milestones=[10, 13], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57934e8d-61b9-4549-ba77-1a1735dec36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, opt, loss_func, train_loader, epochs, scheduler):\n",
    "    history_loss = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        for xb, yb in tqdm(train_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_sum += loss.item()\n",
    "        history_loss.append(loss_sum / len(train_loader))\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}: Train Loss = {history_loss[-1]},  Lr = {scheduler.get_last_lr()}')\n",
    "        \n",
    "    return history_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d52f21-1c06-4407-9199-5d8072241141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff3bf9ec9384d77ac0f6edfe6d8191d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31818216544a43eb826a340ef6109712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 16\n",
    "hist = fit(model, opt, loss_func, train_loader, epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0786a-2090-40b2-85e7-a1641b4341e1",
   "metadata": {},
   "source": [
    "#### predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4f3b6-eef4-4e05-9e96-ebca8f308f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_folder = ImageFolder(root='./data/test_up/', transform=transform)\n",
    "test_loader = DataLoader(test_folder, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3fed4c2-8c55-4bf3-af50-3db7ffdeadbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('./models/model_CIFAR_10_1.pth', map_location=torch.device('cpu'))\n",
    "# import torch\n",
    "# import YourModelClass\n",
    "# model = YourModelClass() \n",
    "# checkpoint = torch.load('./models/model_CIFAR_10_1.pth', map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "file_path = './models/model_CIFAR_10_1.pth'\n",
    "model = Net()\n",
    "checkpoint = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06ac1ad-b29f-4f64-a90d-860f6239a850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f533f19be734aa6ae2d18f89d66e702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, _ in tqdm(test_loader):\n",
    "        output = model(x)\n",
    "        logit = F.softmax(output, dim=1)\n",
    "        _, pred = torch.max(logit, dim=1)\n",
    "        y_pred.append(pred.item())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e15b2585-1d1e-448b-bab6-1fb3b285ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('./data/sampleSubmission.csv')\n",
    "df_sub['label'] = y_pred\n",
    "df_sub.to_csv('CIFAR_ans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9017549-dd5a-442b-ad7b-ebd0973f3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans = pd.read_csv('CIFAR_ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21e7729-ed85-4233-ae48-853747d63c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\"airplane\", \"automobile\", \"bird\",\"cat\", \"deer\", \"dog\",\"frog\",\"horse\", \"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2807d2-143f-41fa-980f-1702dbb576a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = df_ans['label'].tolist()\n",
    "\n",
    "# Use the label_list as an index for class_name\n",
    "indexed_class_name = [class_name[label] for label in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "951178d5-00e5-43b5-a2e3-29317f8d7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans['label'] = indexed_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543ca3f3-fc48-4d1b-9bea-de76c4e7350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans\n",
    "df_ans.to_csv('CIFAR_ans_name.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
